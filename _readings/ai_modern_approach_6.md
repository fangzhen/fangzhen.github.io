---
layout: post
title: 读书笔记 - 人工智能：现代方法 第六部分 沟通、感知和行动
date: 2025-04-27
tags: AI
---
### 第24章总结：自然语言处理

#### 24.1 语言模型
- **概述**：语言模型通过概率分布描述字符串的生成概率，用于预测文本序列、翻译、问答等任务。
- **词袋模型**：基于朴素贝叶斯，假设词之间独立，通过统计词频进行分类，但无法捕捉词序信息。
- **N元词模型**：通过相邻词的依赖关系（如二元、三元模型）提升准确性，适用于分类任务（如情感分析）。
- **平滑技术**：解决低频词和未知词问题，常用拉普拉斯平滑和回退模型。
- **词表示**：从原子模型到结构化表示（如词嵌入），提升泛化能力。

#### 24.2 语法
- **E0语法**：定义简单英语片段的规则，包括名词短语、动词短语等，支持语义和句法分析。
- **词典**：分为开放类（名词、动词等）和封闭类（代词、介词等），后者变化缓慢。

#### 24.3 解析
- **任务**：分析句子结构，构建语法树。
- **CYK算法**：动态规划方法，时间复杂度O(n³)，适用于乔姆斯基范式。
- **依赖解析**：直接表示词间关系，适用于自由语序语言（如拉丁语）。
- **学习解析器**：通过树库（如Penn Treebank）监督学习，或通过无监督方法（如课程学习）从无标注数据中学习。

#### 24.4 增强语法
- **子类别**：通过特征（如主格、单数）细化语法规则，解决歧义。
- **语义解释**：将句子转换为逻辑形式（如一阶逻辑），支持组合语义分析。
- **学习语义语法**：通过问答对或逻辑形式样本训练，如Zettlemoyer和Collins的系统。

#### 24.5 真实语言的复杂性
- **量化**：处理歧义（如“每个代理感受到一阵微风”的不同解释）。
- **语用学**：结合上下文解析指代词和意图（如“我”指说话者）。
- **歧义**：词汇、句法和语义歧义需通过世界模型、语言模型等解决。

#### 24.6 自然语言任务
- **语音识别**：将语音转为文本，基于HMM和深度学习（如WaveNet）。
- **机器翻译**：通过双语语料训练，早期用N元模型，现多用序列到序列模型。
- **信息抽取**：从文本中提取结构化知识（如地址、事件），常用HMM或神经网络。
- **问答系统**：直接生成答案（如“谁创立了美国海岸警卫队？”）。

#### 关键点
1. N元模型在多种任务中表现优异，但需平滑和数据预处理。
2. 层次化结构（如PCFG）和依赖解析各有优势。
3. 增强语法可处理一致性、语义等问题。
4. 真实语言复杂，需结合多模型解决歧义和上下文。

#### 发展历程
- 早期：统计模型（如N元模型）与形式语法（如乔姆斯基）对立。
- 现代：深度学习（如Transformer）推动语音识别、翻译等任务性能提升。

本章展示了自然语言处理的多样性和挑战，从基础模型到复杂任务，强调数据驱动与理论结合的重要性。

### 第25章总结：自然语言处理的深度学习

#### 核心内容
本章探讨了深度学习在自然语言处理（NLP）中的应用，重点介绍了如何通过深度神经网络捕捉语言的结构和灵活性。主要内容包括词嵌入、循环神经网络（RNN）、序列到序列模型、Transformer架构以及预训练与迁移学习。

### 25.1 词嵌入
- **目标**：通过连续向量表示词语，避免手动特征工程，同时捕捉词语之间的语法、语义、主题等关系。
- **方法**：
  - 使用词嵌入（如WORD2VEC、GloVe、FASTTEXT）将词语映射到高维空间，相似词语在空间中距离相近。
  - 词嵌入支持类比推理（如“国王 - 男人 + 女人 ≈ 女王”）。
- **应用**：词嵌入广泛用于NLP任务，可直接使用预训练模型或针对特定任务微调。

### 25.2 自然语言处理中的循环神经网络
- **RNN语言模型**：
  - 通过隐藏状态传递上下文信息，解决固定窗口大小的局限性。
  - 支持可变长度输入，但存在信息丢失或扭曲的问题（如“电话游戏”效应）。
- **LSTM**：
  - 引入门控机制，选择性记忆和遗忘信息，有效处理长距离依赖。
- **双向RNN**：
  - 结合从左到右和从右到左的上下文，提升分类任务（如情感分析）的性能。
- **应用**：RNN可用于词性标注、共指消解等任务。

### 25.3 序列到序列模型
- **基本模型**：
  - 编码器-解码器结构，源语言句子通过编码器转换为隐藏状态，解码器生成目标语言句子。
- **注意力机制**：
  - 动态关注源句子中与当前目标词相关的部分，解决长距离依赖和固定上下文限制。
  - 注意力矩阵可解释性强（如词对齐）。
- **解码**：
  - 贪心解码简单但可能陷入局部最优；束搜索保留多个候选序列，生成更优结果。

### 25.4 Transformer架构
- **自注意力机制**：
  - 通过查询（Query）、键（Key）、值（Value）向量计算词语间的关系，捕捉全局上下文。
  - 多头注意力增强模型对不同语义子空间的理解。
- **位置编码**：
  - 为输入添加位置嵌入，弥补自注意力对词序不敏感的缺陷。
- **优势**：
  - 并行计算高效，支持长距离依赖建模，成为NLP任务的主流架构（如BERT、GPT）。

### 25.5 预训练与迁移学习
- **预训练词嵌入**：
  - 利用无标注文本训练词向量（如GloVe），捕捉词语共现模式。
- **上下文表示**：
  - 通过语言模型（如ELMO、BERT）生成动态词向量，解决多义词问题。
- **掩码语言模型（MLM）**：
  - 随机掩码词语并预测，训练双向上下文表示。
- **应用**：
  - 预训练模型（如T5、ROBERTA）通过微调适配多种任务（如翻译、问答）。

### 25.6 技术现状
- **当前进展**：
  - Transformer模型（如GPT-2、T5）在多项任务中接近或超越人类表现。
  - 系统如ARISTO在科学考试中表现优异，但仍有局限性（如无法处理图表）。
- **挑战与未来**：
  - 模型依赖海量数据，但效率远低于人类学习。
  - 可能的方向包括结合语法与语义的混合方法、扩展多模态数据（如图像、视频）。

### 总结
本章展示了深度学习如何通过词嵌入、RNN、Transformer等模型解决NLP任务，并强调了预训练和迁移学习的重要性。尽管当前模型表现优异，未来仍需在效率、多模态融合和理论理解上取得突破。

# 第26章：机器人学总结

## 本章概述
本章探讨了机器人学的基本概念、技术框架和应用领域。机器人作为物理世界的智能体，通过传感器感知环境并通过执行器影响环境。机器人学问题涉及随机性、部分可观测性和多智能体交互，通常在高维连续状态和动作空间中求解。本章从硬件、感知、规划与控制、人机交互等多个角度系统介绍了机器人学的核心内容。

## 主要内容

### 26.1 机器人
- 机器人是能够操纵物理世界的物理智能体，配备效应器（如轮子、关节）和传感器（如摄像头、雷达）
- 机器人工作环境具有部分可观测性和随机性，通常建模为连续状态空间和动作空间
- 机器人学习面临现实世界的时间约束和安全限制，"仿真到现实"（sim-to-real）是研究热点

### 26.2 机器人硬件
#### 机器人类型
- 机械臂（工业机械臂、辅助机械臂）
- 移动机器人（轮式、腿式、无人机、水下机器人等）
- 其他类型（假肢、外骨骼、群体机器人等）

#### 传感器
- 被动传感器（如摄像头）与主动传感器（如声纳）
- 测距传感器（激光雷达、ToF相机等）
- 定位传感器（GPS、里程计等）
- 本体感受传感器（轴编码器、惯性传感器等）

#### 执行器
- 电动、液压和气动执行器
- 关节类型（旋转关节、棱柱关节等）
- 夹持器设计（平行夹爪、仿人手等）

### 26.3 机器人问题建模
- 机器人问题可建模为MDP（完全可观测）、POMDP（部分可观测）或博弈论模型（多智能体）
- 通常将问题分解为：任务规划、运动规划、控制、偏好学习和人员预测

### 26.4 机器人感知
- 感知将传感器数据映射为环境内部表示
- 定位与建图（SLAM）技术：
  - 蒙特卡洛定位（粒子滤波）
  - 扩展卡尔曼滤波
- 其他感知：温度、气味等环境感知
- 监督与无监督学习在感知中的应用（低维嵌入、自适应感知）

### 26.5 规划与控制
#### 构型空间
- 构型空间表示机器人所有可能状态
- 正向运动学与逆向运动学计算

#### 运动规划
- 可见性图法：保证最短路径
- Voronoi图法：最大化与障碍物距离
- 单元分解法：离散化构型空间
- 随机运动规划（PRM、RRT等）
- 轨迹优化：通过梯度下降优化路径

#### 控制
- 开环控制：基于逆动力学模型
- 闭环控制：PID控制器、计算力矩控制
- 最优控制：LQR、iLQR等

### 26.6 不确定性运动规划
- 处理部分可观测性和随机效应
- 模型预测控制（MPC）：在线重新规划
- 信息收集动作：主动感知环境

### 26.7 机器人中的强化学习
- 挑战：现实世界样本效率低
- 利用模型：基于模型RL、sim-to-real迁移
- 利用其他信息：运动基元、元学习等

### 26.8 人类与机器人
#### 协调问题
- 预测人类行为：建模为近似理性智能体
- 游戏理论框架处理人机交互

#### 学习人类偏好
- 偏好学习：从演示中推断成本函数
- 模仿学习：直接学习策略
- 教学界面：解决对应问题

### 26.9 替代机器人框架
- 反应式控制器：基于有限状态机的直接控制
- 包容架构：组合增广有限状态机（AFSM）

### 26.10 应用领域
- 家庭护理：辅助机器人、假肢等
- 医疗：手术机器人
- 服务：酒店、医院配送机器人
- 自动驾驶汽车
- 娱乐：迪士尼机器人、玩具
- 探索：太空、水下、危险环境
- 工业：工厂自动化

## 关键点
1. 机器人学整合了感知、规划、学习和控制等多个AI领域
2. 连续高维状态空间和现实世界约束是主要挑战
3. 通常采用分层方法分解问题（感知→规划→控制）
4. 人机交互需要协调预测和学习人类偏好
5. 从工业应用到家庭服务，机器人技术正快速渗透各领域

## 发展趋势
- 更强大的sim-to-real迁移技术
- 更自然的人机交互方式
- 深度强化学习在机器人中的应用
- 多机器人协作系统
- 安全可靠的自主决策

### 第27章 计算机视觉总结

#### 引言  
计算机视觉通过摄像头捕捉现实世界的图像，从中提取信息，帮助智能体预测未来、导航、识别物体等。本章介绍了从图像数据中恢复信息的方法。

#### 27.1 简介  
视觉是一种感知通道，通过被动或主动感知（如雷达）获取信息。计算机视觉的核心问题是**重建**（从图像构建世界模型）和**识别**（区分不同对象）。视觉系统依赖于特征提取和基于模型的方法。

#### 27.2 图像形成  
1. **无透镜成像（针孔相机）**：  
   - 针孔相机通过小孔成像，几何模型简单，但图像较暗。  
   - 透视投影公式：\( x = -\frac{fX}{Z} \), \( y = -\frac{fY}{Z} \)，其中 \( f \) 为焦距，\( Z \) 为深度。  
   - 平行线在图像中会聚于消失点。

2. **透镜系统**：  
   - 透镜收集更多光线，形成更亮的图像，但需调整焦距和景深。  
   - 焦平面和景深的概念解释了聚焦范围。

3. **缩放正交投影**：  
   - 当物体深度变化较小时，透视投影可简化为 \( x = sX \), \( y = sY \)，其中 \( s \) 为缩放因子。

4. **光与阴影**：  
   - 光照模型包括环境光、漫反射（Lambert余弦定律）和镜面反射。  
   - 阴影和互反射影响亮度。

5. **颜色**：  
   - 颜色由光谱能量密度表示，人类视觉基于三原色（RGB）原理。  
   - 颜色恒常性指在不同光照下感知物体颜色的能力。

#### 27.3 简单图像特征  
1. **边缘检测**：  
   - 边缘是图像亮度的显著变化，由深度、表面方向、反射或光照变化引起。  
   - 通过高斯滤波平滑图像后计算梯度，标记局部最大值作为边缘。

2. **纹理**：  
   - 纹理是表面的重复模式，通过方向直方图描述。  
   - 纹理可用于物体识别和图像匹配。

3. **光流**：  
   - 光流是视频序列中物体的表观运动，通过匹配相邻帧中的块计算。  
   - 用于估计深度和运动。

4. **图像分割**：  
   - 将图像分为相似区域，基于亮度、颜色或纹理。  
   - 方法包括边界检测和区域聚类（如归一化割）。

#### 27.4 图像分类  
1. **卷积神经网络（CNN）**：  
   - CNN通过多层局部模式检测实现图像分类，如AlexNet在ImageNet竞赛中表现优异。  
   - 数据增强和GPU加速训练。

2. **分类挑战**：  
   - 同一类物体外观差异大（如不同颜色的猫）。  
   - 同一物体在不同条件下外观变化（如光照、视角、遮挡）。

#### 27.5 物体检测  
- **滑动窗口法**：用分类器扫描图像，检测物体。  
- **Faster RCNN**：使用区域提议网络（RPN）生成候选框，通过非极大值抑制和边界框回归优化结果。  
- 评估指标包括准确率和召回率。

#### 27.6 3D世界  
1. **多视图重建**：  
   - 通过匹配多视图中的点恢复3D几何。  
   - 应用包括模型构建、动画混合和路径重建。

2. **双目立体视觉**：  
   - 通过左右眼的视差计算深度，基线 \( b \) 和视差 \( \delta\theta \) 的关系为 \( \delta\theta = \frac{b\delta Z}{Z^2} \)。

3. **单视图几何**：  
   - 从单张图像预测深度图或物体姿态，依赖纹理、阴影和空间关系等线索。

#### 27.7 计算机视觉应用  
1. **行为理解**：  
   - 通过视频分析人体动作，如姿态估计和行为分类。

2. **图像与文字关联**：  
   - 图像标注和描述生成（如COCO数据集），视觉问答（VQA）系统。

3. **三维重建**：  
   - 从多视图或单视图恢复3D结构，用于建筑管理和虚拟现实。

4. **图像生成**：  
   - 风格迁移和生成对抗网络（GAN）生成逼真图像，如深度伪造（deepfake）。

5. **运动控制**：  
   - 视觉用于自动驾驶（车道控制、障碍物避障）和机器人导航（SLAM和路径规划）。

#### 总结  
计算机视觉通过图像处理、特征提取和机器学习，实现了物体识别、三维重建和行为分析等任务。尽管仍面临遮挡、光照变化等挑战，但其应用已广泛渗透到各个领域。

